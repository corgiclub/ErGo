{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U tensorflow tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依赖：\n",
    "# !pip install sentencepiece\n",
    "# !pip install jieba\n",
    "# !pip install regex\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpt2_tokenizer import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    'CPM-Generate/bpe_3w_new/vocab.json',\n",
    "    'CPM-Generate/bpe_3w_new/merges.txt',\n",
    "    model_file='CPM-Generate/bpe_3w_new/chinese_vocab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = hub.load('./cpm-lm-tf2_v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(tokenizer, gpt, sentence, number=1, length=20, top_p=0.9, temperature=0.9):\n",
    "    \"\"\"\n",
    "    numbert: 输出句子个数\n",
    "    length: 输出最大长度\n",
    "    top_p: token的概率排在这以上才有效\n",
    "    temperature: 温度\n",
    "    \"\"\"\n",
    "    inputs = tf.constant([tokenizer.encode(sentence)] * number, dtype=tf.int64)\n",
    "    length = tf.constant(length, dtype=tf.int64)\n",
    "    ret = gpt.signatures['serving_default'](\n",
    "        inp=inputs,\n",
    "        length=length,\n",
    "        top_p=tf.constant(top_p, tf.float32),\n",
    "        temperature=tf.constant(temperature, tf.float32)\n",
    "    )['output_0']\n",
    "    return [\n",
    "        tokenizer.decode(s).replace(' ', '')\n",
    "        for s in ret.numpy()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(question):\n",
    "    q = f'''\n",
    "问题：中国首都是哪里？\n",
    "答案：北京\n",
    "问题：美国的首都是哪里？\n",
    "答案：华盛顿\n",
    "问题：李白在哪个朝代？\n",
    "答案：唐朝\n",
    "问题：{question}\n",
    "答案：'''\n",
    "    ret = sample(tokenizer, gpt, q, 3, 10, top_p=0.9, temperature=0.9)\n",
    "    answers = []\n",
    "    for x in ret:\n",
    "        a = x[len(q):]\n",
    "        a = a.split('\\n')[0]\n",
    "        answers.append(a)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.679 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.679 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['明代', '明朝', '唐伯虎']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('唐伯虎是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['贝克汉姆', '张国荣', '普京']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最帅的是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['孔子', '霍金', '乔达摩·悉达多']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最聪明的人是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['宋朝', '北宋', '北宋']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('李清照是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['关公', '关羽和尉迟恭谁厉害?', '关公']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('关公和秦琼谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['开始投资股票', '办报纸', '卖衣服']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何赚一百万美元？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中餐', '都好吃', '海鲜和烤串']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烧烤和火锅哪个好吃？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['教“国”', '孔子', '帮助孩子成为一个最好的老师']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何成为老师？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['鲸鱼', '海獭', '羚羊']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('佩奇是什么动物？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['两条腿', '三条腿', '两条腿']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('大象有几条腿？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NBA球员迈克尔·乔丹', '6英尺10英寸', '姚明']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('姚明有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['汤姆', '谁强谁弱?', '汤姆']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('汤姆和杰瑞谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['樱桃子是美国人的绰号', '不知道', '不知道']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('野原新之助能打过樱桃子吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['学好了都有出路', '都不好', '不好说']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('学音乐和学画画哪个好？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中文', '中文', '英语']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中文和英文哪个难学？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'Python', 'Java']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('python和java哪个难？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“汗滴禾下土”', '“谁知盘中餐,粒粒皆', '“谁知盘中餐,粒粒皆']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('“锄禾日当午”的下一句是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['鸭', '鸭肉', '鸭肉']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烤鸭的主要原料是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['从最容易的开始', '把大象放冰箱', '先放进冰箱,再放进大象']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('把大象放冰箱总共分几步？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8848米', '6300米', '8844米']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('珠穆朗玛峰有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['珠穆朗玛峰', '珠穆朗玛峰', '珠穆朗玛峰']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最高的山是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一亿多人', '103万', '3亿']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中国有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '人数在160万以上', '672万人']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('日本有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['小米手机', '苹果', '苹果']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('苹果手机好还是华为手机好？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:小红、小明、小丽、小红\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:小明和小红\n",
      "整理:小明\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:一个平时不怎么讲话的女生\n",
      "问题:\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '小明决定去吃饭，小红继续写作业\\n问题：去吃饭的人是谁？\\n答案：', 3, 10, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "熊earth\n",
      "\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟birds\n",
      "爱丽丝alove\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "船boat\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写英文：\\n狗dog\\n猫cat\\n鸟', 3, 10, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默写古诗例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写古诗：\\n白日依山尽，黄河入海流。\\n床前明月光，', 3, 10, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同的角色对话生成例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“怎么着,想打架?”\n",
      "江白:“不\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“说什么呢,哪有这么吃的?”\n",
      "展昭:\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“我没听见这几个字。”\n",
      "柳大洪:\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n佟掌柜：“', 3, 20, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“我要给你生个孩子!”\n",
      "“孩子!”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“不是,是咱‘一言为定’!”\n",
      "\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“嗯,嗯,好,我回家了。”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n白展堂：“', 3, 20, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“现在别叫了,我想起来了,知道,知道!\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“你个死鬼,敢骗我!”\n",
      "沈浪:\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“他好像也喜欢我。”\n",
      "徐天:“\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n莫小贝：“', 3, 20, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“阿舅,你真不是人,我要去找我妈,你快拦\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“啊!那就一言为定,我走我的阳关道,你\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“我没文化,我有文化,我是文化人!”\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n李白：“', 3, 20, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "俄国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "英国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "朝鲜\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '中国的首都是北京\\n日本的首都是东京\\n美国的首都是', 3, 3, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是元\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李白所在朝代是唐\\n李清照所在朝代是宋\\n唐伯虎所在朝代是', 3, 1, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '陈奕迅是歌星\\n郭德纲是', 3, 1, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "珠穆朗玛峰的高度(米)是8351。\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是1432.786。<eod>诗词:新\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是多少?(如果和世界最高峰珠\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '珠穆朗玛峰的高度（米）是', 3, 10, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姚明的身高(米)是六英尺四英寸,因为\n",
      "--------------------\n",
      "姚明的身高(米)是多少?请分别说明姚明的身高\n",
      "--------------------\n",
      "姚明的身高(米)是NBA球员中最高的,所以是中\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '姚明的身高（米）是', 3, 10, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算数例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=12\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n2+2=4\\n3+3=6\\n4+4=', 3, 1, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n1+2=3\\n1+3=4\\n1+4=', 3, 1, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "天崩地裂紫金锤\n",
      "天昏地暗紫金锤\n",
      "三魂被震散\n",
      "紫电被震散\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "冲天三式斩雷斧\n",
      "幻影这紫电玄焰\n",
      "九龙金锤\n",
      "且看圣天之上斩\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "玄罡这丹药\n",
      "玄真这烈火\n",
      "玄真这丹药\n",
      "仙灵没利爪\n",
      "玄真没\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''惊雷这通天修为\n",
    "天塌地陷紫金锤\n",
    "紫电这玄真火焰\n",
    "''', 3, 30, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写作文例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱情是一定要三观一致的,不然就算再相爱也会觉得累。但我男朋友要出国读研,和他在一起我一直都觉得要么我和他在一起,要\n",
      "--------------------\n",
      "爱情是美好的,但是婚姻不一定美好。现实很残酷,人心很虚,这一点我很清楚。我在做自己想做的事情,不伤害别人,也不委屈自己。\n",
      "--------------------\n",
      "爱情是付出,你我彼此互相爱,互相依赖,互相包容,互相支持,共同努力,共同承担,遇到困难,想到对方,想到对方的好,自己的不好\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''爱情是''', 3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。方家的人亦进不来,似乎贾母房中的众姊妹们原封不动带进来,所以知道。\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。这贾母王夫人等,不是宝玉等,也不是老太太王夫人,却是姨太太的丈夫,姨太太的妻子,宝玉等不过是他们的小辈,他们的妻妾。黛玉见了这般,心中更觉惊奇,只是笑道:“姨太太住的是咱们这边正房,我是荣国府的人,不便进去的。”说着,便走至贾母那边,拉着贾母,只说要去,贾母也没料到她会来,便道:“我那边没人,是我小老婆的丈夫,他们一家子搬到这边来住了。”宝玉笑道:“原来你们那边也有\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。再回头看看贾母,忙忙的张罗着自己收拾屋子,桌上放着大笔银子,舅母宝玉那里送来的。这里我们可以看到,贾母住的大房子的房顶是四角的,其中靠外的两角是院子,住的是贾母,住的是二房的贾敏,贾敏住的是正房的三间,贾母住的是外间,四间有大花的厅子,五间有小花的厅子,住的是丫头媳妇,其中三间住的是宝玉,贾母住的是正房的三间,贾敏住的是外间,在这里,小花厅的住的是鸳鸯,内间住的是林黛玉。这还不算\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''一时黛玉进了荣府，下了车。众嬷嬷引着，便往东转弯，穿过一个东西的穿堂，向南大厅之后，仪门内大院落，上面五间大正房，两边厢房鹿顶耳房钻山，四通八达，轩昂壮丽，比贾母处不同。黛玉便知这方是正经正内室，一条大甬路，直接出大门的。''',\n",
    "    3, 200, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“今天我想吃火锅”\n",
      "B:“你想吃什么火锅?”\n",
      "A:“火锅”\n",
      "B:“哦,那吃鱼吧”\n",
      "A:“鱼”\n",
      "B:“\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“哦,那我知道了”\n",
      "A:“咱们一起去吃火锅吧”\n",
      "B:“还是算了吧,我吃过了”\n",
      "A\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“我想吃烤鱼”\n",
      "C:“我想吃烤鸭”\n",
      "D:“我想吃鸡排”\n",
      "E:“我想吃日式拉面”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''A：“今天我想吃火锅”\n",
    "B：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“跟我一起去看电影吧”\n",
      "B:“好啊”\n",
      "A:“看什么电影?”\n",
      "B:“《贞子3D》”\n",
      "A:“原来你是SHE的歌迷,\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“嗯,好”\n",
      "A:“去电影院吗?”\n",
      "B:“是的”\n",
      "A:“你不是单身吗?”\n",
      "B:\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“好啊”\n",
      "A:“其实我还不知道你是谁,你叫什么名字?”\n",
      "B:“(⊙o⊙)...”\n",
      "A\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''A：“跟我一起去看电影吧”\n",
    "B：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对联例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "duilian = '''\n",
    "上联天，下联地\n",
    "上联雨，下联风\n",
    "上联大陆，下联长空\n",
    "上联雷隐隐，下联雾蒙蒙\n",
    "上联开心大吉，下联万事亨通\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联杜甫作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联李白作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联杜甫作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联杜甫作诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联李白作赋\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联李白作诗，下联',\n",
    "    5, 2, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联只要有福\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联拒绝早恋\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联吃牢饭\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联幸福一生\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联享尽富贵\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联追求真爱，下联',\n",
    "    5, 4, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联白日青天\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联天天向上\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联长命百岁\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联平平安安\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联夜夜同欢\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天天向上，下联',\n",
    "    5, 4, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联万事皆休\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联风雪在我怀\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联我心在天地\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联天地都是家\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联地久天长\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天地在我心，下联',\n",
    "    5, 4, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名人名言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅曾经说过:“问题不在主义,而在于主义之下的中国社会。”面对外国的“新文化运动”,我们该如何对待呢?胡适、鲁迅\n",
      "--------------------\n",
      "鲁迅曾经说过:“中国人的性情是总喜欢调和、折中的。譬如你说,这屋子太暗,说在这里开一个天窗,大家一定是不允许的。但如果你主张拆\n",
      "--------------------\n",
      "鲁迅曾经说过:“志摩是个乐观主义者,他总是以开朗的笑容面对生活,即使碰上了不顺心的事,他也很快会抛到脑后。”3\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''鲁迅曾经说过：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱因斯坦曾经说过:“唯物主义者,只有唯物主义者,才可称得上哲学家。”唯物主义也是无神论,它从宗教的宗教立场出发,研究自然和人类社会的规律,如人\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“科学的尽头是哲学,哲学的尽头是宗教。”爱因斯坦说这句话的意思是,如果你试图用一个方法来解决一个问题,那么你的最终目标肯定是错误\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“在我们的发展过程中,不断学习,因为学习的成果是不可估量的,我们应该不断地从别人的研究成果中吸取营养,就像纳豆、大枣、山药\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''爱因斯坦曾经说过：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "牛顿曾经说过:“在自然科学的历史上,许多伟大的人物,都是在受了科学家的启发之后,才发奋地去从事研究的。”一个伟大的科学家,对于科学家的\n",
      "--------------------\n",
      "牛顿曾经说过:“凡能够称为哲学的,都可以称为科学。”这一点早就被否定了。现在流行的哲学流派,大部分都不是科学。我并不反对\n",
      "--------------------\n",
      "牛顿曾经说过:“我一生的科学工作就是把真理变成人类能够懂得的语言。”科学不仅仅是一个探索真理的过程,还是人类探索真理的一条捷径。我们每个人\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''牛顿曾经说过：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "佛祖曾经说过:“人皆可以为尧舜,但我不可以。”所以王阳明到底还是失败了。这让王阳明在内心颇为沮丧,同时又无法释怀。\n",
      "--------------------\n",
      "佛祖曾经说过:“我给你一颗痣,你要还给我。”唐僧听到,慌忙跪在地上,问佛祖:“你给我一颗痣,我也要还给你吗\n",
      "--------------------\n",
      "佛祖曾经说过:“如果一个人说他没有钱,那不是很没面子吗?”这话我是赞同的,谁都会这么说,但我想说的是,如果一个人在说这句话的\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''佛祖曾经说过：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乔布斯曾经说过:“如果你不理解为什么会有人这么做,那么你就没必要去理解。如果你真的想理解为什么会有人这么做,那么你就得先去理解。”—\n",
      "--------------------\n",
      "乔布斯曾经说过:“你不会用过了,再来后悔。”“不要为打翻的牛奶哭泣”(教父)我\n",
      "--------------------\n",
      "乔布斯曾经说过:“我们在我认为是伟大产品中,并不看重它的功能,我们看重的是是否解决了问题。”那么你有没有发现,“解决问题”这个前提\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''乔布斯曾经说过：“''',\n",
    "    3, 50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
